This challenge was completed on a Ubuntu 22.04 VM running logstash 8.3.3.  

This pipeline configuration is written to input via stdin as the challenge only dictates a single line message for parsing which made that convenient for testing. However, included is an example realistic input for security telemetry as outlined using the HTTP Input filter. The message is then processed using a custom grok filter leaving the remaining key value pairs in a seperate field.  Not sure if this was as intentioned but was a convenient way to then have a single field that gets parse as key value pairs.  Next the message is mutated to first remove redundant fields (I was particualarily unsure of this) for the sake of removing redundant data, then the fields requiring renaming are changed.  Finally a translate filter is applied to convert the value of the severity field to a corresponding description.  Also, the included JSON output shows testing with additional severity values.  Finally that data is output to a file and added to a new line for readability.  0